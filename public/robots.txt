# robots.txt for https://deenbytes.com

# Allow all bots to crawl everything
User-agent: *
Disallow:

# Optional: Block image indexing by Google
User-agent: Googlebot-Image
Disallow: /

# Optional: Block specific bad/spammy bots (optional - adjust based on your traffic analysis)
User-agent: Baiduspider
Disallow: /

User-agent: Yeti
Disallow: /

User-agent: Naverbot
Disallow: /

User-agent: ia_archiver
Disallow: /

# End of robots.txt
